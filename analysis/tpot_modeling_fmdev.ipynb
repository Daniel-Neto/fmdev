{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "from dask.distributed import Client\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_csv(\"data/base.csv\", sep=';')\n",
    "df = df_temp[['VAR01', 'VAR02', 'VAR03', 'VAR04', 'VAR05',\n",
    "              'VAR06', 'VAR07', 'VAR08', 'VAR09', 'VAR10',\n",
    "              'VAR12', 'VAR14', 'VAR15', 'VAR16', 'VAR17',\n",
    "              'VAR18', 'VAR19', 'VAR20', 'VAR21', 'VAR22',\n",
    "              'VAR23', 'VAR24', 'VAR25', 'VAR28', 'VAR30',\n",
    "              'VAR31', 'VAR31b', 'VAR31c', 'VAR32a', 'VAR32b',\n",
    "              'VAR32c', 'VAR32d', 'VAR33', 'VAR34', 'VAR35', 'DESEMPENHO_BINARIO', 'ID do Aluno']]\n",
    "\n",
    "df = df.rename(columns={\"DESEMPENHO_BINARIO\": \"Y\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"VAR17\"] = df[\"VAR17\"].astype(str).replace(',','.')\n",
    "df[\"VAR24\"] = df[\"VAR24\"].astype(str).replace(',','.')\n",
    "df[\"VAR25\"] = df[\"VAR25\"].astype(str).replace(',','.')\n",
    "df[\"VAR30\"] = df[\"VAR30\"].astype(str).replace(',','.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"VAR17\"] = df[\"VAR17\"].astype(float)\n",
    "df[\"VAR24\"] = df[\"VAR24\"].astype(float)\n",
    "df[\"VAR25\"] = df[\"VAR25\"].astype(float)\n",
    "df[\"VAR30\"] = df[\"VAR30\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df)) < 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "del test['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDtest = test[\"ID do Aluno\"].reset_index()\n",
    "test = test.drop(labels = [\"ID do Aluno\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train[\"Y\"]\n",
    "X_train = train.drop(labels = [\"Y\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimizer = TPOTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimizer = TPOTClassifier(generations=5, population_size=20, cv=5,\n",
    "                                    random_state=42, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=120.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8871493469987939\n",
      "Generation 2 - Current best internal CV score: 0.8871493469987939\n",
      "Generation 3 - Current best internal CV score: 0.8871493469987939\n",
      "Generation 4 - Current best internal CV score: 0.8871493469987939\n",
      "Generation 5 - Current best internal CV score: 0.8880479828762657\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(CombineDFs(input_matrix, SGDClassifier(VarianceThreshold(input_matrix, threshold=0.001), alpha=0.01, eta0=0.1, fit_intercept=True, l1_ratio=0.75, learning_rate=constant, loss=perceptron, penalty=elasticnet, power_t=0.1)), bootstrap=False, criterion=gini, max_features=0.6500000000000001, min_samples_leaf=14, min_samples_split=6, n_estimators=100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
       "               disable_update_check=False, early_stop=None, generations=5,\n",
       "               max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
       "               mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
       "               periodic_checkpoint_folder=None, population_size=20,\n",
       "               random_state=42, scoring=None, subsample=1.0, template=None,\n",
       "               use_dask=False, verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_optimizer.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=120.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving periodic pipeline from pareto front to data/tpot-output/pipeline_gen_1_idx_0_2020.03.25_00-26-02.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [00:26:02] /private/var/folders/kg/56jlft1d2ts2r4l5v96sv18h0000gn/T/pip-install-_qm87u0a/xgboost/xgboost/src/learner.cc:946: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000013280c9e0 dmlc::LogMessageFatal::~LogMessageFatal() + 112\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001328a7576 xgboost::LearnerImpl::ConfigureNumFeatures() + 822\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000013289decf xgboost::LearnerImpl::Configure() + 1119\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000013289e459 xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*) + 121\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x0000000132805e8a XGBoosterUpdateOneIter + 122\n",
      "  [bt] (5) 6   _ctypes.cpython-37m-darwin.so       0x00000001104330d7 ffi_call_unix64 + 79\n",
      "  [bt] (6) 7   ???                                 0x00007ffee12cef80 0x0 + 140732676239232\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "Generation 1 - Current Pareto front scores:\n",
      "-1\t0.8885965845924328\tXGBClassifier(input_matrix, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=10, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.6000000000000001)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-1\t0.8885965845924328\tXGBClassifier(input_matrix, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=10, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.6000000000000001)\n",
      "-3\t0.8886435329492406\tXGBClassifier(MaxAbsScaler(StandardScaler(input_matrix)), XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=10, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.6000000000000001)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Saving periodic pipeline from pareto front to data/tpot-output/pipeline_gen_2_idx_1_2020.03.25_00-28-17.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['VAR01', 'VAR02', 'VAR03', 'VAR04', 'VAR05', 'VAR06', 'VAR07', 'VAR08', 'VAR09', 'VAR10', 'VAR12', 'VAR14', 'VAR15', 'VAR16', 'VAR17', 'VAR18', 'VAR19', 'VAR20', 'VAR21', 'VAR22', 'VAR23', 'VAR24', 'VAR25', 'VAR28', 'VAR30', 'VAR31', 'VAR31b', 'VAR31c', 'VAR32a', 'VAR32b', 'VAR32c', 'VAR32d', 'VAR33', 'VAR34', 'VAR35', 'ID do Aluno'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35']\n",
      "expected VAR32a, VAR12, VAR35, VAR34, VAR33, VAR25, VAR31b, VAR32c, VAR07, VAR03, VAR19, VAR31c, VAR09, VAR21, VAR10, VAR14, VAR08, VAR16, VAR30, VAR20, VAR32d, VAR31, VAR01, VAR32b, VAR18, VAR23, VAR17, VAR02, VAR06, VAR05, VAR15, ID do Aluno, VAR04, VAR24, VAR28, VAR22 in input data\n",
      "training data did not have the following fields: f30, f31, f7, f35, f34, f12, f3, f1, f13, f21, f32, f24, f14, f26, f15, f27, f6, f10, f25, f33, f17, f23, f28, f0, f29, f9, f19, f22, f16, f5, f8, f11, f18, f20, f2, f4.\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-1\t0.8885965845924328\tXGBClassifier(input_matrix, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=10, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.6000000000000001)\n",
      "-3\t0.8886435329492406\tXGBClassifier(MaxAbsScaler(StandardScaler(input_matrix)), XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=10, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.6000000000000001)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [00:31:20] /private/var/folders/kg/56jlft1d2ts2r4l5v96sv18h0000gn/T/pip-install-_qm87u0a/xgboost/xgboost/src/learner.cc:946: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000013280c9e0 dmlc::LogMessageFatal::~LogMessageFatal() + 112\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001328a7576 xgboost::LearnerImpl::ConfigureNumFeatures() + 822\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000013289decf xgboost::LearnerImpl::Configure() + 1119\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000013289e459 xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*) + 121\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x0000000132805e8a XGBoosterUpdateOneIter + 122\n",
      "  [bt] (5) 6   _ctypes.cpython-37m-darwin.so       0x00000001104330d7 ffi_call_unix64 + 79\n",
      "  [bt] (6) 7   ???                                 0x00007ffee12cef80 0x0 + 140732676239232\n",
      "\n",
      ".\n",
      "Generation 4 - Current Pareto front scores:\n",
      "-1\t0.8885965845924328\tXGBClassifier(input_matrix, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=10, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.6000000000000001)\n",
      "-3\t0.8890660351060442\tXGBClassifier(StandardScaler(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=10, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.6000000000000001)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Saving periodic pipeline from pareto front to data/tpot-output/pipeline_gen_4_idx_1_2020.03.25_00-38-31.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Error in callback <function DaskDistributedBackend.apply_async.<locals>.callback_wrapper at 0x144d53440> of <Future: cancelled, key: _tree_query_parallel_helper-batch-75eff486e95a454896eecf58bca18a3b>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 285, in execute_callback\n",
      "    fn(fut)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_dask.py\", line 260, in callback_wrapper\n",
      "    result = future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 222, in result\n",
      "    raise result\n",
      "concurrent.futures._base.CancelledError: _tree_query_parallel_helper-batch-75eff486e95a454896eecf58bca18a3b\n",
      "distributed.client - ERROR - Error in callback <function DaskDistributedBackend.apply_async.<locals>.callback_wrapper at 0x142253830> of <Future: cancelled, key: _tree_query_parallel_helper-batch-01ec431c1e5e444982542a06231e5974>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 285, in execute_callback\n",
      "    fn(fut)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_dask.py\", line 260, in callback_wrapper\n",
      "    result = future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 222, in result\n",
      "    raise result\n",
      "concurrent.futures._base.CancelledError: _tree_query_parallel_helper-batch-01ec431c1e5e444982542a06231e5974\n",
      "distributed.client - ERROR - Error in callback <function DaskDistributedBackend.apply_async.<locals>.callback_wrapper at 0x140db49e0> of <Future: cancelled, key: _tree_query_parallel_helper-batch-fc8e558fa1dd4ba5981d4cfc1e891298>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 285, in execute_callback\n",
      "    fn(fut)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_dask.py\", line 260, in callback_wrapper\n",
      "    result = future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 222, in result\n",
      "    raise result\n",
      "concurrent.futures._base.CancelledError: _tree_query_parallel_helper-batch-fc8e558fa1dd4ba5981d4cfc1e891298\n",
      "distributed.client - ERROR - Error in callback <function DaskDistributedBackend.apply_async.<locals>.callback_wrapper at 0x143fb9050> of <Future: cancelled, key: _tree_query_parallel_helper-batch-fb120533fa6b400d9a0007afcd293603>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 285, in execute_callback\n",
      "    fn(fut)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_dask.py\", line 260, in callback_wrapper\n",
      "    result = future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 222, in result\n",
      "    raise result\n",
      "concurrent.futures._base.CancelledError: _tree_query_parallel_helper-batch-fb120533fa6b400d9a0007afcd293603\n",
      "distributed.client - ERROR - Error in callback <function DaskDistributedBackend.apply_async.<locals>.callback_wrapper at 0x143aabc20> of <Future: cancelled, type: builtins.list, key: _tree_query_parallel_helper-batch-fac71b5e33d64fc195fd47c7a046c0f0>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 285, in execute_callback\n",
      "    fn(fut)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_dask.py\", line 260, in callback_wrapper\n",
      "    result = future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 222, in result\n",
      "    raise result\n",
      "concurrent.futures._base.CancelledError: _tree_query_parallel_helper-batch-fac71b5e33d64fc195fd47c7a046c0f0\n",
      "distributed.client - ERROR - Error in callback <function DaskDistributedBackend.apply_async.<locals>.callback_wrapper at 0x143fb9170> of <Future: cancelled, key: _tree_query_parallel_helper-batch-9af2dd2edc694752b1dce96093f43b26>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 285, in execute_callback\n",
      "    fn(fut)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_dask.py\", line 260, in callback_wrapper\n",
      "    result = future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 222, in result\n",
      "    raise result\n",
      "concurrent.futures._base.CancelledError: _tree_query_parallel_helper-batch-9af2dd2edc694752b1dce96093f43b26\n",
      "distributed.client - ERROR - Error in callback <function DaskDistributedBackend.apply_async.<locals>.callback_wrapper at 0x144813320> of <Future: cancelled, key: _tree_query_parallel_helper-batch-c89d48888fb1406db4a883ac42ce7b9e>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 285, in execute_callback\n",
      "    fn(fut)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_dask.py\", line 260, in callback_wrapper\n",
      "    result = future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 222, in result\n",
      "    raise result\n",
      "concurrent.futures._base.CancelledError: _tree_query_parallel_helper-batch-c89d48888fb1406db4a883ac42ce7b9e\n",
      "distributed.client - ERROR - Error in callback <function DaskDistributedBackend.apply_async.<locals>.callback_wrapper at 0x144d60dd0> of <Future: cancelled, key: _tree_query_parallel_helper-batch-821f116ed5c7466cb37400ee4b354084>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 285, in execute_callback\n",
      "    fn(fut)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_dask.py\", line 260, in callback_wrapper\n",
      "    result = future.result()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/distributed/client.py\", line 222, in result\n",
      "    raise result\n",
      "concurrent.futures._base.CancelledError: _tree_query_parallel_helper-batch-821f116ed5c7466cb37400ee4b354084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 _tree_query_parallel_helper-batch-75eff486e95a454896eecf58bca18a3b.\n",
      "Generation 5 - Current Pareto front scores:\n",
      "-1\t0.8885965845924328\tXGBClassifier(input_matrix, XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=10, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.6000000000000001)\n",
      "-2\t0.8886435219310858\tXGBClassifier(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), XGBClassifier__learning_rate=0.01, XGBClassifier__max_depth=10, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.6000000000000001)\n",
      "-3\t0.893619882480363\tXGBClassifier(StandardScaler(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), XGBClassifier__learning_rate=0.1, XGBClassifier__max_depth=10, XGBClassifier__min_child_weight=6, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.6000000000000001)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Saving periodic pipeline from pareto front to data/tpot-output/pipeline_gen_5_idx_1_2020.03.25_00-51-57.py\n",
      "Saving periodic pipeline from pareto front to data/tpot-output/pipeline_gen_5_idx_2_2020.03.25_00-51-57.py\n",
      "\r"
     ]
    }
   ],
   "source": [
    "# connect to the cluster\n",
    "client = Client(processes=False) \n",
    "\n",
    "# create the estimator normally\n",
    "estimator = TPOTClassifier(generations=5, population_size=20, cv=5,\n",
    "                                    random_state=42, verbosity=3, \n",
    "                                    use_dask=True,\n",
    "                                    periodic_checkpoint_folder=\"data/tpot-output/\")\n",
    "\n",
    "# perform the fit in this context manager\n",
    "with joblib.parallel_backend(\"dask\"):\n",
    "    estimator.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
      "               disable_update_check=False, early_stop=None, generations=5,\n",
      "               max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
      "               mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
      "               periodic_checkpoint_folder='data/tpot-output/',\n",
      "               population_size=20, random_state=42, scoring=None, subsample=1.0,\n",
      "               template=None, use_dask=True, verbosity=3, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
